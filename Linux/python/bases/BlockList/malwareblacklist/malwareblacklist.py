import os
import requests
from bs4 import BeautifulSoup
from datetime import datetime

RESULT = []

def geturltext(url):
    try:
        r = requests.get(url)
    except:
        return ''
    else:
        return r.text

def process(text):
    soup = BeautifulSoup(text, 'lxml')
    table = soup.find("table", {"class" : "Table"})
    mlwr = table.find_all('tr')[1:]
    for ml in mlwr:
        rows = ml.find_all('td')
        if(len(rows) > 8):
            date = rows[0].text
            url = rows[1].text
            registrar = rows[2].text
            ip = rows[3].text
            asn = rows[4].text
            hosting = rows[5].text
            try:
                cn = rows[6].find('img').get('title')
            except:
                cn = '-'
            dl = rows[7].text
            submitted = rows[8].text
            RESULT.append([date, url, registrar, ip, asn, hosting, cn, dl, submitted])

def savetofile():
    name = datetime.now().strftime("%Y-%m-%d_%H_%M") + '.csv'
    f = open(name, 'w')
    for line in RESULT:
        f.write((line[0] +', '+ line[1] +', '+ line[2] + ', '+
                line[3] +', '+ line[4] +', '+ line[5] + ', '+ 
                line[6] +', '+ line[7] +', '+ line[8]).encode('utf-8').strip() + '\n')
    f.close()

def getTotalPage(text):
    try:
        soup = BeautifulSoup(text, 'html.parser')
        table = soup.find('table')
        td = table.find_all('a')
        return int(td[1].text)
    except:
        return 0

def main():
    url = 'http://www.malwareblacklist.com/showAllMalwareURL.php?pageNo='
    firstPageText = geturltext(url+'1')
    totalPage = getTotalPage(firstPageText)
    for x in range(totalPage):
        pageText = geturltext(url + str(x+1))
        process(pageText) 
    savetofile()

if(__name__ == '__main__'):
    main()
